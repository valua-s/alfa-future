from __future__ import annotations

import json
import time
from collections import OrderedDict, defaultdict
from functools import lru_cache
from pathlib import Path
from typing import Callable, List, Optional, Sequence

import typer
from rich.console import Console
from rich.layout import Layout
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel
from rich.table import Table
from rich.text import Text
from rich.tree import Tree

from agent.config import ModelSpec, llama_config
from agent.core.agent_logger import agent_logger
from agent.core.llm import get_llm_stats, reset_llm_stats
from agent.core.model_downloader import model_downloader
from agent.core.model_manager import model_manager
from agent.core.state import AgentState, initial_state
from agent.tools.document_loader import DocumentLoader
from agent.tools.legal_rag import legal_rag_tool
try:
    import tiktoken
except ImportError:  # pragma: no cover - optional dependency
    tiktoken = None  # type: ignore[assignment]


app = typer.Typer(add_completion=False)
models_app = typer.Typer(help="–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GGUF –º–æ–¥–µ–ª—è–º–∏")
app.add_typer(models_app, name="models")
console = Console()
document_loader = DocumentLoader()

NODE_LABELS = {
    "planner": "–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫",
    "executor": "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å",
    "reflector": "–†–µ—Ñ–ª–µ–∫—Ç–æ—Ä",
    "synthesizer": "–°–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä",
    "document_loader": "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
}

NODE_ICONS = {
    "planner": "üß†",
    "executor": "‚öôÔ∏è",
    "reflector": "üîÅ",
    "synthesizer": "üßæ",
    "document_loader": "üìÑ",
}

MODEL_TARGETS: Sequence[tuple[str, str, ModelSpec]] = (
    ("orchestrator", "–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä", llama_config.orchestrator),
    ("executor", "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å", llama_config.executor),
)
MODELS_READY = False


def ensure_models(download: bool = True) -> None:
    """Ensure all required GGUF weights exist locally."""

    global MODELS_READY
    if MODELS_READY:
        return

    missing: List[tuple[str, ModelSpec]] = []
    for _, label, spec in MODEL_TARGETS:
        path = llama_config.base_dir / spec.filename
        if not path.exists():
            missing.append((label, spec))

    if missing:
        if not download:
            names = ", ".join(f"{label} ({spec.filename})" for label, spec in missing)
            raise RuntimeError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –º–æ–¥–µ–ª–∏: {names}")
        with console.status("–°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏..."):
            for label, spec in missing:
                model_downloader.ensure(spec)
                console.print(f"[green]–°–∫–∞—á–∞–Ω {label} ‚Äî {spec.filename}[/green]")
    MODELS_READY = True


def run_query(query: str, files: List[Path]) -> AgentState:
    ensure_models()
    reset_llm_stats()
    state = initial_state(query, [str(path) for path in files])
    if files:
        doc_rows = _collect_file_metadata(state, files)
        if doc_rows:
            state["loaded_documents"] = doc_rows
            _print_documents_table(doc_rows)
    console.rule("[bold]–°—Ç–∞—Ä—Ç –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞[/bold]")
    layout, live_callback = _build_live_view()
    agent_logger.subscribe(live_callback)
    try:
        with Live(layout, console=console, refresh_per_second=4, transient=True):
            result = _agent_graph().invoke(state)
    finally:
        agent_logger.reset_subscribers()
    result["llm_stats"] = get_llm_stats().to_dict()
    result["llm_backend"] = model_manager.backend_report()
    return result


@lru_cache(maxsize=1)
def _agent_graph():
    from agent.core.graph import agent_graph as graph

    return graph


@app.command(context_settings={"allow_extra_args": True})
def query(
    ctx: typer.Context,
    text: str = typer.Argument(..., help="–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"),
    files: List[Path] = typer.Option(
        [],
        "--files",
        "-f",
        help="–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—É—Ç–µ–π —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –ø–æ—Å–ª–µ –æ–ø—Ü–∏–∏)",
    ),
) -> None:
    """–û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞."""

    extra_files = [Path(arg) for arg in ctx.args]
    all_files = list(files) + extra_files
    result = run_query(text, all_files)
    events = result.get("events", [])
    if events:
        _print_timeline(events)
        _print_call_tree(events)
        _print_tool_summary(result.get("tool_results", []), events)
    if llm_calls := result.get("llm_calls"):
        _print_llm_breakdown(llm_calls)
    if plan := result.get("plan"):
        console.print(Panel(json.dumps(plan, ensure_ascii=False, indent=2), title="–ü–ª–∞–Ω"))
    if tools := result.get("tool_results"):
        console.print(Panel(json.dumps(tools, ensure_ascii=False, indent=2), title="–•–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"))
    if answer := result.get("final_answer"):
        console.print(Markdown(answer))
    if trace := result.get("langsmith_run_id"):
        console.print(f"[bold green]Trace:[/bold green] {trace}")
    _print_stats(result.get("llm_stats"), backend=result.get("llm_backend"))


@app.command()
def interactive() -> None:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è."""

    console.print("[bold]–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º. –í–≤–µ–¥–∏—Ç–µ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞.[/bold]")
    files: List[Path] = []
    while True:
        user = console.input("[bold blue]–í—ã[/bold blue]: ")
        if user.strip().lower() in {"exit", "quit"}:
            break
        if user.startswith("load "):
            _, _, path = user.partition(" ")
            file_path = Path(path.strip())
            if file_path.exists():
                files.append(file_path)
                console.print(f"[green]–î–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª {file_path}[/green]")
            else:
                console.print(f"[red]–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω[/red]")
            continue
        result = run_query(user, files)
        console.print(Markdown(result.get("final_answer", "–Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞")))
        _print_stats(result.get("llm_stats"))


@app.command("index-documents")
def index_documents(
    directory: Path = typer.Argument(..., exists=True, file_okay=False, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏"),
) -> None:
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ RAG –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""

    count = legal_rag_tool.index_documents(directory)
    console.print(f"[green]–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {count}[/green]")


SLOT_LABELS = {"orchestrator": "–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä", "executor": "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å"}


def _print_stats(stats: dict | None, *, backend: dict | None = None) -> None:
    if not stats:
        return

    table = Table("–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ")
    table.add_row("–í—ã–∑–æ–≤–æ–≤ LLM", str(stats.get("calls", 0)))
    table.add_row(
        "–¢–æ–∫–µ–Ω—ã (prompt / completion / total)",
        f"{stats.get('prompt_tokens', 0)} / {stats.get('completion_tokens', 0)} / {stats.get('total_tokens', 0)}",
    )
    table.add_row(
        "–í—Ä–µ–º—è (prompt / eval, ms)",
        f"{stats.get('prompt_ms', 0.0)} / {stats.get('eval_ms', 0.0)}",
    )
    table.add_row("–°–∫–æ—Ä–æ—Å—Ç—å, —Ç–æ–∫/—Å", f"{stats.get('tokens_per_second', 0.0)}")
    console.print(Panel(table, title="LLM —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"))
    if backend:
        _print_backend_info(backend)


def _print_backend_info(backend: dict) -> None:
    table = Table("–°–ª–æ—Ç", "–†–µ–∂–∏–º")
    for slot, layers in backend.items():
        label = SLOT_LABELS.get(slot, slot)
        if layers is None or layers < 0:
            mode = "–Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
        elif layers > 0:
            mode = f"GPU ({layers} —Å–ª–æ—ë–≤)"
        else:
            mode = "CPU"
        table.add_row(label, mode)
    console.print(Panel(table, title="LLM Backend"))


_TOKEN_ENCODER = None


def _ensure_token_encoder():
    global _TOKEN_ENCODER
    if _TOKEN_ENCODER is not None:
        return _TOKEN_ENCODER
    if tiktoken is None:
        return None
    try:
        _TOKEN_ENCODER = tiktoken.get_encoding("cl100k_base")
    except Exception:  # pragma: no cover - fallback path
        _TOKEN_ENCODER = None
    return _TOKEN_ENCODER


def _estimate_tokens(text: str) -> int:
    encoder = _ensure_token_encoder()
    if encoder is None:
        return max(1, len(text) // 4) if text else 0
    try:
        return len(encoder.encode(text))
    except Exception:  # pragma: no cover - encoding edge cases
        return max(1, len(text) // 4) if text else 0


def _collect_file_metadata(state: AgentState, files: List[Path]) -> List[dict]:
    rows: List[dict] = []
    for file_path in files:
        try:
            record = document_loader.load_file(file_path)
        except Exception as exc:
            console.print(f"[red]–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {file_path}: {exc}[/red]")
            continue
        row = _build_document_row(file_path, record)
        rows.append(row)
        agent_logger.log_document_load(
            state,
            path=row["path"],
            metadata={
                "type": row["type"],
                "size_bytes": row["size_bytes"],
                "lines": row["lines"],
                "tokens": row["tokens"],
            },
        )
    return rows


def _build_document_row(path: Path, record: dict) -> dict:
    text = record.get("text", "") or ""
    metadata = record.get("metadata", {}) or {}
    size_bytes = path.stat().st_size if path.exists() else 0
    lines = text.count("\n") + 1 if text else 0
    doc_type = metadata.get("type") or path.suffix.lower().lstrip(".") or "unknown"
    return {
        "path": str(path),
        "type": doc_type,
        "size": _format_bytes(size_bytes),
        "size_bytes": size_bytes,
        "lines": lines,
        "tokens": _estimate_tokens(text),
    }


def _print_documents_table(rows: List[dict]) -> None:
    if not rows:
        return
    table = Table("–§–∞–π–ª", "–¢–∏–ø", "–†–∞–∑–º–µ—Ä", "–°—Ç—Ä–æ–∫", "~–¢–æ–∫–µ–Ω–æ–≤")
    for row in rows:
        table.add_row(
            row["path"],
            row["type"],
            row["size"],
            str(row["lines"]),
            str(row["tokens"]),
        )
    console.print(Panel(table, title="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"))


def _format_bytes(size_bytes: int) -> str:
    units = ["–ë", "–ö–ë", "–ú–ë", "–ì–ë"]
    value = float(size_bytes)
    for unit in units:
        if value < 1024 or unit == units[-1]:
            if unit == "–ë":
                return f"{int(value)} {unit}"
            return f"{value:.2f} {unit}"
        value /= 1024
    return f"{value:.2f} –ì–ë"


def _build_live_view() -> tuple[Layout, Callable[[AgentState, dict], None]]:
    layout = Layout()
    layout.split_column(
        Layout(name="current", size=7),
        Layout(name="history"),
    )
    layout["current"].update(Panel(Text("–û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π..."), title="–¢–µ–∫—É—â–∏–π —à–∞–≥"))
    layout["history"].update(Panel(Text("–ó–∞–ø—É—Å–∫–∞–µ–º –≥—Ä–∞—Ñ..."), title="–ü—Ä–æ–≥—Ä–µ—Å—Å"))

    def _on_event(state: AgentState, event: dict) -> None:
        layout["current"].update(Panel(_format_current_event(event), title="–¢–µ–∫—É—â–∏–π —à–∞–≥"))
        layout["history"].update(Panel(_build_progress_tree(state.get("events", [])), title="–ü—Ä–æ–≥—Ä–µ—Å—Å"))

    return layout, _on_event


def _format_current_event(event: dict | None) -> Text:
    if not event:
        return Text("–û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π...")
    title, lines = _describe_event(event)
    txt = Text()
    txt.append(title + "\n", style="bold")
    for line in lines:
        txt.append(f"{line}\n", style="dim")
    return txt


def _build_progress_tree(events: List[dict]) -> Tree | Text:
    if not events:
        return Text("–°–æ–±—ã—Ç–∏–π –ø–æ–∫–∞ –Ω–µ—Ç.")
    tree = Tree("–ü–æ—Å–ª–µ–¥–Ω–∏–µ —à–∞–≥–∏")
    for event in events[-12:]:
        title, lines = _describe_event(event)
        branch = tree.add(title)
        for line in lines[:3]:
            branch.add(line)
    return tree


def _format_event_label(event: dict) -> str:
    title, _ = _describe_event(event)
    return title


def _print_timeline(events: List[dict]) -> None:
    if not events:
        return
    start_ts = events[0].get("timestamp") or time.time()
    table = Table("#", "t+–º—Å", "–ù–æ–¥–∞", "–°–æ–±—ã—Ç–∏–µ", "–î–µ—Ç–∞–ª–∏")
    for idx, event in enumerate(events, start=1):
        delta = int(((event.get("timestamp") or start_ts) - start_ts) * 1000)
        details = event.get("details") or {}
        detail_text = ", ".join(f"{k}={v}" for k, v in list(details.items())[:3]) or "‚Äî"
        table.add_row(
            str(idx),
            f"+{delta}",
            event.get("node", "‚Äî"),
            event.get("event_type", "‚Äî"),
            detail_text,
        )
    console.print(Panel(table, title="Timeline"))


def _print_call_tree(events: List[dict]) -> None:
    if not events:
        return
    tree = Tree("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã–∑–æ–≤–æ–≤")
    grouped: OrderedDict[str, List[dict]] = OrderedDict()
    for event in events:
        grouped.setdefault(event.get("node", "unknown"), []).append(event)
    for node, node_events in grouped.items():
        branch = tree.add(_node_display_name(node))
        for event in node_events:
            title, lines = _describe_event(event)
            child = branch.add(title)
            for line in lines[:2]:
                child.add(line)
    console.print(Panel(tree, title="Call Tree"))


def _print_tool_summary(tool_results: List[dict], events: List[dict]) -> None:
    if not tool_results:
        return
    stats = defaultdict(lambda: {"calls": 0, "errors": 0, "duration": 0.0})
    for row in tool_results:
        tool = row.get("tool", "unknown")
        stats[tool]["calls"] += 1
        if not row.get("success", True):
            stats[tool]["errors"] += 1
    for event in events:
        if event.get("event_type") == "tool_call":
            details = event.get("details") or {}
            tool = details.get("tool", "unknown")
            stats[tool]["duration"] += float(details.get("duration_ms", 0.0))
    table = Table("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç", "–í—ã–∑–æ–≤–æ–≤", "–û—à–∏–±–æ–∫", "Œ£ –≤—Ä–µ–º—è, –º—Å")
    for tool, data in stats.items():
        table.add_row(
            tool,
            str(data["calls"]),
            str(data["errors"]),
            f"{data['duration']:.1f}",
        )
    console.print(Panel(table, title="–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã"))


def _print_llm_breakdown(llm_calls: List[dict]) -> None:
    if not llm_calls:
        return
    stats = defaultdict(lambda: {"calls": 0, "prompt": 0, "completion": 0, "total": 0, "duration": 0.0})
    for call in llm_calls:
        slot = call.get("slot", "orchestrator")
        stats[slot]["calls"] += 1
        stats[slot]["prompt"] += int(call.get("prompt_tokens", 0))
        stats[slot]["completion"] += int(call.get("completion_tokens", 0))
        stats[slot]["total"] += int(call.get("total_tokens", 0))
        stats[slot]["duration"] += float(call.get("duration_ms", 0.0))
    table = Table("–°–ª–æ—Ç", "–í—ã–∑–æ–≤–æ–≤", "Prompt/Completion", "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤", "Œ£ –≤—Ä–µ–º—è, –º—Å")
    for slot, data in stats.items():
        table.add_row(
            slot,
            str(data["calls"]),
            f"{data['prompt']} / {data['completion']}",
            str(data["total"]),
            f"{data['duration']:.1f}",
        )
    console.print(Panel(table, title="LLM Breakdown"))


def _describe_event(event: dict) -> tuple[str, list[str]]:
    node = event.get("node", "unknown")
    event_type = event.get("event_type", "")
    details = event.get("details") or {}
    lines: list[str] = []
    node_label = _node_display_name(node)

    if event_type == "node_enter":
        title = f"{node_label} ‚Üí —Å—Ç–∞—Ä—Ç"
    elif event_type == "node_exit":
        duration = details.get("duration_ms")
        human = f"{duration:.0f} –º—Å" if duration is not None else "‚Äî"
        title = f"{node_label} ‚Üí —Ñ–∏–Ω–∏—à"
        lines.append(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {human}")
    elif event_type == "tool_call":
        tool = details.get("tool", "tool")
        success = details.get("success", True)
        icon = "‚úÖ" if success else "‚ö†Ô∏è"
        duration = details.get("duration_ms")
        title = f"{icon} –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool}"
        if duration is not None:
            lines.append(f"–í—Ä–µ–º—è: {duration:.0f} –º—Å")
        if error := details.get("error"):
            lines.append(f"–û—à–∏–±–∫–∞: {error}")
    elif event_type == "document_load":
        path = Path(details.get("path", ""))
        title = f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞: {path.name or path}"
        doc_type = details.get("type")
        if doc_type:
            lines.append(f"–¢–∏–ø: {doc_type}")
        size = details.get("size_bytes")
        if size:
            lines.append(f"–†–∞–∑–º–µ—Ä: {_format_bytes(int(size))}")
    elif event_type == "llm_call":
        slot = details.get("slot", "orchestrator")
        title = f"üß© LLM: {slot}"
        lines.append(f"–¢–æ–∫–µ–Ω—ã: {details.get('total_tokens', 0)}")
        lines.append(f"–í—Ä–µ–º—è: {details.get('duration_ms', 0):.0f} –º—Å")
    elif event_type == "llm_call_pending":
        slot = details.get("slot", "orchestrator")
        title = f"üß© LLM (–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞): {slot}"
        preview = details.get("prompt_preview")
        if preview:
            lines.append("–ü—Ä–æ–º–ø—Ç: " + preview[:80].replace("\n", " "))
        lines.append("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è / –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç...")
    else:
        title = f"{node_label} ‚Ä¢ {event_type}"
        for key, value in list(details.items())[:3]:
            lines.append(f"{key}: {value}")

    return title, lines


def _node_display_name(node: str) -> str:
    label = NODE_LABELS.get(node, node.capitalize())
    icon = NODE_ICONS.get(node, "‚Ä¢")
    return f"{icon} {label}"


def _status_table() -> Table:
    table = Table("–†–æ–ª—å", "–§–∞–π–ª", "–†–∞–∑–º–µ—Ä", "–°—Ç–∞—Ç—É—Å")
    for _, label, spec in MODEL_TARGETS:
        path = llama_config.base_dir / spec.filename
        exists = path.exists()
        size = f"{path.stat().st_size / (1024**3):.2f} –ì–ë" if exists else "‚Äî"
        status = "[green]‚úÖ[/green]" if exists else "[red]–Ω–µ—Ç[/red]"
        table.add_row(label, spec.filename, size, status)
    return table


@models_app.command("status")
def models_status() -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π."""

    console.print(_status_table())


def _resolve_target(role: str) -> tuple[str, ModelSpec]:
    for key, label, spec in MODEL_TARGETS:
        if key == role:
            return label, spec
    raise typer.BadParameter("role –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å orchestrator –∏–ª–∏ executor")


@models_app.command("download")
def models_download(
    role: Optional[str] = typer.Option(
        None, "--role", "-r", help="orchestrator | executor (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –æ–±–µ –º–æ–¥–µ–ª–∏)"
    ),
) -> None:
    """–°–∫–∞—á–∞—Ç—å –Ω—É–∂–Ω—ã–µ GGUF-–º–æ–¥–µ–ª–∏ –∑–∞—Ä–∞–Ω–µ–µ."""

    targets = []
    if role:
        targets.append(_resolve_target(role))
    else:
        targets = [(label, spec) for _, label, spec in MODEL_TARGETS]

    console.print("[cyan]–°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)...[/cyan]")
    for label, spec in targets:
        path = model_downloader.ensure(spec)
        size = f"{path.stat().st_size / (1024**3):.2f} –ì–ë"
        console.print(f"[green]{label} –≥–æ—Ç–æ–≤–∞ ({path.name}, {size})[/green]")



def main() -> None:
    app()


if __name__ == "__main__":
    main()


